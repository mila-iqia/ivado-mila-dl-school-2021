{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "week1_data__to_complete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCQs5y60YyRv"
      },
      "source": [
        "# IVADO-Mila Deep Learning School\n",
        "# Spring 2021\n",
        "# Tutorial: Introduction to data processing for machine learning experiments\n",
        "\n",
        "## Authors: \n",
        "\n",
        "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
        "\n",
        "Francis Grégoire\n",
        "\n",
        "Gaétan Marceau Caron <gaetan.marceau.caron@mila.quebec>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fsFqgdJZ2Mh"
      },
      "source": [
        "# Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGZRSQojc5zc"
      },
      "source": [
        "This tutorial aims to emphasize the importance of understanding the dataset associated with a machine learning (ML) project. This understanding will help you consider valuable operations to do before training your ML models. It serves as a gentle introduction to data exploration and covers basic things that every machine learning practitioner should know.\n",
        "\n",
        "**Note: the purpose of this tutorial is to be introductory. Thus, we propose simple solutions to our exercises. In practice, you should use more advanced techniques to train your models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8LaHzDHEcWX"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeIkku61EgF4"
      },
      "source": [
        "Before we begin, we must install all the required libraries for this part of the tutorial. To do so, we will use the `pip` utility. Execute the cell below by selecting it and pressing `shift`+`Enter`. (This operation may take a few minutes.)\n",
        "\n",
        "We need to be using the latest version of `pillow` for this tutorial. If you are prompted with:\n",
        "\n",
        "> WARNING: The following packages were previously imported in this runtime:\n",
        "  [PIL]\n",
        "You must restart the runtime in order to use newly installed versions.\n",
        "\n",
        "Then click on restart runtime and rerun the cells afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNlYWG6z9GKT",
        "scrolled": true
      },
      "source": [
        "!pip3 install torch torchvision matplotlib\n",
        "!pip3 install --upgrade pillow==8.1.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKufekB4FnqN"
      },
      "source": [
        "To ensure that all required libraries are available, let's try to load all libraries and modules we will need during this tutorial by executing this cell: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJzEY8Q2XQbL"
      },
      "source": [
        "import importlib\n",
        "required_libraries = ['torch', 'torchvision', 'PIL', 'matplotlib']\n",
        "for lib in required_libraries:\n",
        "    if importlib.util.find_spec(lib) is None:\n",
        "        print(\"%s unavailable\" % lib)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYn7wiPyF0RT"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "print(\"Torch version: \", torch.__version__)\n",
        "print(\"GPU Available: {}\".format(use_gpu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn7fGc3PgWUy"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8dhsflQg4MB"
      },
      "source": [
        "In this tutorial, we will use the [CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10) dataset. It is a collection of 32 x 32 color images in 10 different classes. The 10 different (indexed-)classes are the following:\n",
        "0. airplane;\n",
        "1. automobile;\n",
        "2. bird;\n",
        "3. cat;\n",
        "4. deer;\n",
        "5. dog;\n",
        "6. frog;\n",
        "7. horse;\n",
        "8. ship;\n",
        "9. truck.\n",
        "\n",
        "The task of interest in this tutorial is an image classification task. We are interested in finding the class associated with a given image. We will use [PyTorch](https://pytorch.org/) as the ML framework.\n",
        "\n",
        "At this stage, we provide as-is all functions and related PyTorch methods. This tutorial is not about learning PyTorch but instead focuses on understanding data and basic ML concepts. In the following tutorials, you will learn how to develop, train, and evaluate models on different data types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUgpszup1kCy"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj3bQ5iM51BY"
      },
      "source": [
        "## Data retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjpnx7t81vKD"
      },
      "source": [
        "In this section, we provide a function for downloading the CIFAR-10 dataset. It takes as input two arguments:\n",
        "- **path**: the directory where the downloaded dataset will be saved.\n",
        "- **train_flag**: boolean flag indicating whether to download data from the training set (`train_flag=True`) or the test set (`train_flag=False`).\n",
        "\n",
        "It returns two elements, namely:\n",
        "- **imgs**: NumPy array representing the downloaded images of size N x 32 x 32 x 3 where N is the number of images.\n",
        "- **labels**: list of N (indexed-)classes, each associated with a single image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KctjRqgm2Fze"
      },
      "source": [
        "def download_CIFAR10(path, train_flag):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     path: the directory where the dowloaded dataset will be saved.\n",
        "     train_flag: if `True`, download data from training set, otherwise\n",
        "        download from test set.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of two elements (imgs, labels) where\n",
        "        imgs: a numpy array of shape N x 32 x 32 x 3 where N is the number of images.\n",
        "        labels: list of N (indexed-)classes, each  associated with a single image.\n",
        "  \n",
        "  \"\"\"\n",
        "  dataset = torchvision.datasets.CIFAR10(\n",
        "      root=path, train=train_flag, download=True\n",
        "  )\n",
        "  imgs, labels = dataset.data, dataset.targets\n",
        "  return imgs, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRY0tkh79h48"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Download the CIFAR-10 dataset and retrieve the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30NO1znU3eDK"
      },
      "source": [
        "imgs, labels = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9RrkHB3-anO"
      },
      "source": [
        "Retrieve the CIFAR-10 test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPQBZhzl3qZp"
      },
      "source": [
        "test_imgs, test_labels = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nbcM9SC-8MX"
      },
      "source": [
        "## Data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY2fanet_dMf"
      },
      "source": [
        "In the previous section, we provide functions to download the **train** and **test** datasets. Usually, we need three sets of data in a ML project: train, **validation**, and test sets. Unfortunately, the CIFAR-10 dataset does not contain a preprocessed validation set; therefore, we need to create a **custom** one by sampling from the **training** set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLxTIkNeCHA3"
      },
      "source": [
        "In this section, we provide a function for creating a validation set from the original training set. It takes as input five arguments:\n",
        "- **imgs**: NumPy array representing the image set from which the partitioning is made.\n",
        "- **labels**: labels associated with the provided image set.\n",
        "- **valid_ratio** (optional): a portion of the data that will be used for the validation set. Default: `0.3`.\n",
        "- **shuffle** (optional): whether or not the data need to be shuffled before the partitioning is made. Default: `True`.\n",
        "- **seed** (optional): the seed of the random generator. Default: `1234`.\n",
        "\n",
        "It provides as output 4 elements, which are:\n",
        "- **train_imgs**: NumPy array representing the images of the training set after the splitting is done.\n",
        "- **train_labels**: labels associated with the images of the training set.\n",
        "- **valid_imgs**: NumPy array representing the images of the validation set after the splitting is done.\n",
        "- **valid_labels**: labels associated with the images of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_LYjCXrEql1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def partition_dataset(imgs, labels, valid_ratio=0.3, shuffle=True, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     imgs: numpy array representing the image set from which \n",
        "        the partitioning is made.\n",
        "     labels: the labels associated with the provided images.\n",
        "     valid_ratio (optional): the portion of the data that will be used in\n",
        "        the validation set. Default: 0.3.\n",
        "     shuffle (optional): whether or not to shuffle the data. Default: True.\n",
        "     seed (optional): the seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of 4 elements (train_imgs, train_labels, valid_imgs, valid_labels)\n",
        "     where:\n",
        "        train_imgs: a numpy array of images for the training set.\n",
        "        train_labels: labels associated with the images in the training set.\n",
        "        valid_imgs: a numpy array of images for the validation set.\n",
        "        valid_labels: labels associated with the images in the validation set.\n",
        "  \n",
        "  \"\"\"\n",
        "  if shuffle:\n",
        "    np.random.seed(seed)  # Set the random seed of numpy.\n",
        "    indices = np.random.permutation(imgs.shape[0])\n",
        "  else:\n",
        "    indices = np.arange(imgs.shape[0])\n",
        "  \n",
        "  train_idx, valid_idx = np.split(\n",
        "      indices, \n",
        "      [int((1.0 - valid_ratio)*len(indices))]\n",
        "  )\n",
        "  train_imgs, valid_imgs = imgs[train_idx], imgs[valid_idx]\n",
        "  tgt = np.array(labels)\n",
        "  train_labels, valid_labels = tgt[train_idx].tolist(), tgt[valid_idx].tolist()\n",
        "  return train_imgs, train_labels, valid_imgs, valid_labels\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ-K7scKNWo0"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Generate the custom training and validation sets by using `partition_dataset` with the default parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYhh6Cb9ILc2"
      },
      "source": [
        "train_imgs, train_labels, valid_imgs, valid_labels = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d3B5YMVNucn"
      },
      "source": [
        "## Data visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgUkFNKcPS8I"
      },
      "source": [
        "Before training any model, it is always good to visualize the data first. In particular, visualizing the data distribution will provide valuable insights into the data at hand. \n",
        "\n",
        "This section provides some functions for visualizing image data and computing the label distribution within a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac8QuRoHhGql"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_image(img):\n",
        "  \"\"\"\n",
        "  Plot a single image.\n",
        "  \n",
        "  Args:\n",
        "     img: image to be plotted.\n",
        "     \n",
        "  \"\"\"\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "def plot_random_images(imgs, n):  \n",
        "  \"\"\"\n",
        "  Randomly sample n images from an image set and plot them in a grid.\n",
        "  \n",
        "  Args:\n",
        "     imgs: collection of images from which sampling will be made.\n",
        "     n: the number of images to be sampled.\n",
        "     \n",
        "  \"\"\"\n",
        "  sampled_indices = np.random.choice(imgs.shape[0], n, False)\n",
        "  sampled_images = imgs[sampled_indices]\n",
        "  \n",
        "  sampled_images = np.transpose(sampled_images, (0, 3, 1, 2))\n",
        "  sampled_tensor = torch.Tensor(sampled_images)\n",
        "  \n",
        "  grid_tensor = torchvision.utils.make_grid(\n",
        "      sampled_tensor, normalize=True, value_range=(0, 255)\n",
        "  )\n",
        "  grid_tensor = np.transpose(grid_tensor.numpy(), (1, 2, 0))\n",
        "  \n",
        "  plot_image(grid_tensor)\n",
        "  \n",
        "  \n",
        "def plot_dataset_histogram(labels, title='Label distribution', rel_freq=False):\n",
        "  \"\"\"\n",
        "  Plot the histogram/distribution of the labels within a dataset.\n",
        "  \n",
        "  Args:\n",
        "     labels: collection of labels from which the distribution is computed.\n",
        "     title: the title of the histogram.\n",
        "     rel_freq: if true, the histogram is normalized to show relative frequencies\n",
        "               otherwise, it shows the frequencies.\n",
        "     \n",
        "  \"\"\"\n",
        "  _ = plt.hist(labels, bins=np.arange(11)-0.5, rwidth=0.85, density=rel_freq)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Label')\n",
        "  if rel_freq:\n",
        "    plt.ylabel('Relative frequency')\n",
        "  else:\n",
        "    plt.ylabel('Frequency')\n",
        "  plt.xticks(np.arange(10))\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVKSaRGphrBS"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Use the previously defined functions to visualize samples from training and validation sets. Also, compute the label distributions for these two sets. Comment on your observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cHN_c43Uu6U"
      },
      "source": [
        "# plot a given sample from the training dataset and retrieve its label\n",
        "... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVSI7FQozT7Y"
      },
      "source": [
        "Observations:\n",
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Y3if2UaZxm"
      },
      "source": [
        "# plot random samples (e.g. 16) from the training dataset\n",
        "... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4MtyWh_0hPl"
      },
      "source": [
        "Observations:\n",
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZJ_maHlITUo"
      },
      "source": [
        "# plot the label distribution of the training dataset\n",
        "... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whIHwKKB2FW_"
      },
      "source": [
        "Observations:\n",
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Ygn8fsjXho"
      },
      "source": [
        "## Shuffling data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWmG02g-GrZF"
      },
      "source": [
        "It is essential to **shuffle** the dataset before partitioning it into training, validation and test sets to remove spurious correlations due to the ordering. Remember the dataset should **independently** and identically distributed.\n",
        "\n",
        "The CIFAR-10 dataset downloaded at the beginning of this tutorial was already shuffled. To visualize the importance of shuffling, suppose we observe the following label distributions after splitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqPnb5avjXzA"
      },
      "source": [
        "sorted_idx = np.argsort(labels)\n",
        "sorted_imgs = imgs[sorted_idx]\n",
        "sorted_labels = [labels[i] for i in sorted_idx]\n",
        "\n",
        "_, sorted_train_labels, _, sorted_valid_labels = partition_dataset(sorted_imgs, sorted_labels,\n",
        "                                                                   valid_ratio=0.3, shuffle=False)\n",
        "plot_dataset_histogram(sorted_train_labels, 'Train set label distribution')\n",
        "plot_dataset_histogram(sorted_valid_labels, 'Valid set label distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnFiOFAqC_Xr"
      },
      "source": [
        "### Exercise 4\n",
        "What will be the consequences of using these training and validation sets on the performance metrics?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N75a0RHI3OkF"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES-dzdF8jfaW"
      },
      "source": [
        "Below, we shuffle the data and observe that the labels are evenly distributed in the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwcyQ7zJja0x"
      },
      "source": [
        "_, shuffled_train_labels, _, shuffled_valid_labels = partition_dataset(\n",
        "    sorted_imgs, sorted_labels, valid_ratio=0.3, shuffle=True\n",
        ")\n",
        "\n",
        "plot_dataset_histogram(\n",
        "    shuffled_train_labels, 'Train set label distribution', rel_freq=True)\n",
        "\n",
        "plot_dataset_histogram(\n",
        "    shuffled_valid_labels, 'Valid set label distribution', rel_freq=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU25Ban6jiWe"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D0nw531G1wn"
      },
      "source": [
        "As you will see in the next tutorials, to train and evaluate models, we use **dataloaders**. Since deep learning requires heavy data transformations, we want tools that efficiently **transform**, **shuffle**, and **batch** our datasets with the option to use multiprocessing workers. A dataloader is an optimized data iterator that provides all these features.\n",
        "\n",
        "Modern deep learning frameworks, such as PyTorch and TensorFlow, offer very efficient dataloaders out of the box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK1zZ2qanmol"
      },
      "source": [
        "We show a simple example of preparing a dataloader using a small subset of our training set. During training, it is best practice to shuffle the data at the beginning of each **epoch** (each processing of the entire training set is referred to as an epoch). Thus, we usually set `shuffle=True` for training and `shuffle=False` for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOrqUB8Fjif-"
      },
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def create_dataset(images, labels, n):\n",
        "  \"\"\"\n",
        "  Slice the first n images/labels and create a torch.utils.data.DataLoader.\n",
        "  \n",
        "  Args:\n",
        "     images: numpy array of images.\n",
        "     labels: list of labels associated with the images.\n",
        "     n: the number of images/labels to slice.\n",
        "        \n",
        "  Return:\n",
        "     A torch.utils.data.TensorDataset to be used with a torch.utils.data.DataLoader.\n",
        "     \n",
        "  \"\"\"\n",
        "  imgs = torch.tensor(images[:n], dtype=torch.float)\n",
        "  labels = torch.tensor(labels[:n], dtype=torch.long)\n",
        "  dataset = TensorDataset(imgs, labels)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "n = 100\n",
        "batch_size = 32\n",
        "train_dataset = create_dataset(train_imgs, train_labels, n)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch {}/{}:'.format(epoch+1, epochs))\n",
        "  for i, (x, y) in enumerate(train_dataloader):\n",
        "    print('   batch {}/{} of {} examples.'.format(i+1, int(np.ceil(n/batch_size)), y.size(0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7p5cEgevRLi"
      },
      "source": [
        "Thus, we can easily iterate over the the training set for many epochs with a simple `for` loop. At every iteration of the loop, the dataloader returns a mini-batch of `batch_size` input-label pairs `(x, y)`.\n",
        "\n",
        "By setting `drop_last=False`, the last incomplete batch is kept if the dataset size is not divisible by `batch_size`. When training a model, we average the loss of the examples of a mini-batch. Having 4 examples in the last mini-batch instead of 32 gives more weight to these 4 examples than the other examples. In practice, if we shuffle the training set at each epoch, we mitigate this bias since different examples will have the chance to be in the last mini-batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwpEr_1iers"
      },
      "source": [
        "# Training with neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e32z51jvlgRJ"
      },
      "source": [
        "This section provides two methods for training and evaluating neural networks. We will use these methods for studying the impact of dataset size and unbalanced classes on models' performances. For this tutorial, we don't need to understand the implementation of these methods. These will be covered in the following tutorials.\n",
        "\n",
        "The first method, `training_on_dataset`, trains a model on a given dataset. It takes as input the following arguments and returns a **trained model**:\n",
        "- **imgs**: images the model will be trained on.\n",
        "- **labels**: labels associated with the provided images.\n",
        "- **eval_imgs**: images to evaluate the model.\n",
        "- **eval_labels**: labels associated with the images used to evaluate the model.\n",
        "- **epochs**: number of epochs during the training (number of times to loop over the whole set of images/labels).\n",
        "- **batch_size** (optional): size of a mini-batch. Default: `8`.\n",
        "- **lr** (optional): learning rate. Default: `1e-3`.\n",
        "- **seed** (optional): the seed of the random generator. Default: `1234`.\n",
        "- **transformations** (optional): transformations to apply to the images during the training process. Default: `None`.\n",
        "- **label_weights** (optional): importance weights associated with each label. Default: `None` (all labels are treated equally).\n",
        "- **metrics** (optional): metrics to monitor during training. Default: `None`.\n",
        "\n",
        "The second one, `evaluate_classes`, evaluates a trained model on a given dataset. It takes as input the following arguments and returns the **evaluation performance**:\n",
        "- **net**: the trained model to be evaluated.\n",
        "- **imgs**: images the model will be evaluated on.\n",
        "- **labels**: ground truth labels associated with the provided images for performance computation.\n",
        "- **batch_size** (optional): size of a mini-batch. Default: `8`.\n",
        "- **metrics** (optional): performance metrics to compute. Default: `None`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWaFOMsdo4Sj"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "classe_names = (\n",
        "    'plane', 'car', 'bird', 'cat', 'deer', \n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        ")\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Compute the accuracy score.\n",
        "  \n",
        "  Args:\n",
        "     y_true: ground truth labels.\n",
        "     y_pred: predicted labels by a classifier.\n",
        "     \n",
        "  Return:\n",
        "     Accuracy score.\n",
        "     \n",
        "  \"\"\"\n",
        "  return metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Compute the F1 score.\n",
        "  \n",
        "  Args:\n",
        "     y_true: ground truth labels.\n",
        "     y_pred: predicted labels by a classifier.\n",
        "     \n",
        "  Return:\n",
        "     F1 score.\n",
        "     \n",
        "  \"\"\"\n",
        "  return metrics.f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "\n",
        "def plot_metric(train_values, valid_values, name=''):\n",
        "  \"\"\"\n",
        "  Plot the values of a given metric on training and validation sets.\n",
        "  \n",
        "  Args:\n",
        "     train_values: values of the metric on the training set. \n",
        "     valid_values: values of the metric on the validation set.\n",
        "     name: name of the metric.\n",
        "  \"\"\"\n",
        "  x = range(len(train_values))\n",
        "  plt.plot(x, train_values, label='train')\n",
        "  plt.plot(x, valid_values, label='valid')\n",
        "  plt.title(name)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "class AugmentBasedDataset(Dataset):\n",
        "  \"\"\"Encapsulated dataset for data augmentation.\"\"\"\n",
        "\n",
        "  def __init__(self, dataset, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        dataset: dataset on which to perform data augmentation.\n",
        "        transform (callable, optional): optional transform to be applied\n",
        "            on a sample.\n",
        "\n",
        "    \"\"\"\n",
        "    self.dataset = dataset\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img, label = self.dataset[idx]\n",
        "    if self.transform:\n",
        "        img = self.transform(img)\n",
        "    return img, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKCGEYWIpW3n"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"Basic CNN used for image classification.\"\"\"\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm19z0tk1j8e"
      },
      "source": [
        "def training_on_dataset(imgs, labels, eval_imgs, eval_labels,\n",
        "                        epochs, batch_size=8, lr=1e-3,\n",
        "                        seed=1234, transformations=None, label_weights=None,\n",
        "                        metrics=None, verbose=True):\n",
        "  \"\"\"Black box function to train a neural network on CIFAR-10 dataset.\"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  \n",
        "  # Train data.\n",
        "  train_imgs = ((imgs/255.0) - 0.5) * 2.0  # Normalize to [-1, 1].\n",
        "  train_imgs = np.transpose(train_imgs, (0, 3, 1, 2))\n",
        "  train_labels = np.array(labels)\n",
        "  \n",
        "  train_dataset = TensorDataset(\n",
        "      torch.from_numpy(train_imgs).float(), \n",
        "      torch.from_numpy(train_labels).long()\n",
        "  )\n",
        "  train_dataset = AugmentBasedDataset(train_dataset, transformations)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # Eval data.\n",
        "  eval_imgs = ((eval_imgs/255.0) - 0.5) * 2.0 # Normalize to [-1, 1]\n",
        "  eval_imgs = np.transpose(eval_imgs, (0, 3, 1, 2))\n",
        "  eval_labels = np.array(eval_labels)\n",
        "  \n",
        "  eval_dataset = TensorDataset(\n",
        "      torch.from_numpy(eval_imgs).float(), \n",
        "      torch.from_numpy(eval_labels).long()\n",
        "  )\n",
        "  eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  net = Net()\n",
        "  net = net.to(device)\n",
        "  if label_weights is not None:\n",
        "    label_weights = torch.tensor(label_weights).float()\n",
        "    label_weights = label_weights.to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weight=label_weights)\n",
        "  optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "  \n",
        "  train_loss_values = []\n",
        "  eval_loss_values = []\n",
        "  train_metric_values = None\n",
        "  eval_metric_values = None\n",
        "  \n",
        "  if metrics is not None:\n",
        "    if isinstance(metrics, dict):\n",
        "      train_metric_values = {metric: [] for metric in metrics.keys()}\n",
        "      eval_metric_values = {metric: [] for metric in metrics.keys()}\n",
        "    elif isinstance(metrics, (list, tuple)):\n",
        "      train_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "      eval_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "    else:\n",
        "      metrics = [metrics]\n",
        "      train_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "      eval_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "\n",
        "  for epoch in range(epochs):  # Loop over the dataset.\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    n_update = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data in train_dataloader:\n",
        "      # data is a tuple of (inputs, targets).\n",
        "      inputs, targets = data\n",
        "      \n",
        "      if targets.numel() > 1:\n",
        "        y_true.extend(targets.flatten().tolist())\n",
        "      else:\n",
        "        y_true.append(targets.flatten().tolist())\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)       \n",
        "\n",
        "      # Reset the parameter gradients.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward + backward + optimize.\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Predict label.\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      if predicted.numel() > 1:\n",
        "        y_pred.extend(predicted.flatten().tolist())\n",
        "      else:\n",
        "        y_pred.append(predicted.flatten().tolist())\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      n_update += 1\n",
        "\n",
        "    # Save and print statistics at the end of each training epoch.\n",
        "    train_loss = running_loss / n_update\n",
        "    train_loss_values.append(train_loss)\n",
        "    eval_loss, eval_true, eval_pred = evaluate_during_training(net, criterion, eval_dataloader)\n",
        "    eval_loss_values.append(eval_loss)\n",
        "    \n",
        "    if metrics is not None:\n",
        "      for metric in metrics.keys():\n",
        "        train_metric_values[metric].append(metrics[metric](y_true, y_pred))\n",
        "        eval_metric_values[metric].append(metrics[metric](eval_true, eval_pred))\n",
        "  \n",
        "    if verbose:\n",
        "      print('[Epoch {}/{}] Training loss: {:.3f} | Validation loss: {:.3f}' \n",
        "            .format(epoch + 1, epochs, train_loss, eval_loss)\n",
        "      )\n",
        "    running_loss = 0.0\n",
        "    n_update = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "  \n",
        "  if verbose:\n",
        "    plot_metric(train_loss_values, eval_loss_values, 'Loss')\n",
        "    if metrics is not None:\n",
        "      for metric in metrics.keys():\n",
        "        plot_metric(train_metric_values[metric], eval_metric_values[metric], metric)\n",
        "  \n",
        "  return net\n",
        "\n",
        "\n",
        "def evaluate_during_training(net, criterion, dataloader):\n",
        "  net.eval()\n",
        "  running_loss = 0.0\n",
        "  n_update = 0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  for data in dataloader:\n",
        "    inputs, targets = data\n",
        "    if targets.numel() > 1:\n",
        "      y_true.extend(targets.flatten().tolist())\n",
        "    else:\n",
        "      y_true.append(targets.flatten().tolist())\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device) \n",
        "    with torch.no_grad():\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)  \n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      if predicted.numel() > 1:\n",
        "        y_pred.extend(predicted.flatten().tolist())\n",
        "      else:\n",
        "        y_pred.append(predicted.flatten().tolist())\n",
        "      running_loss += loss.item()\n",
        "      n_update += 1\n",
        "  eval_loss = running_loss / n_update\n",
        "  return eval_loss, y_true, y_pred\n",
        "\n",
        "\n",
        "def evaluate_classes(net, imgs, labels, batch_size=8, metrics=None, verbose=True):\n",
        "  \"\"\"Black box function to evaluate a neural network on CIFAR-10 dataset.\"\"\"\n",
        "  normalized_imgs = ((imgs/255.0) - 0.5) * 2.0 # Normalize to [-1, 1]\n",
        "  normalized_imgs = np.transpose(normalized_imgs, (0, 3, 1, 2))\n",
        "  arr_labels = np.array(labels)\n",
        "  \n",
        "  dataset = TensorDataset(\n",
        "      torch.from_numpy(normalized_imgs).float(), \n",
        "      torch.from_numpy(arr_labels).long()\n",
        "  )\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "  \n",
        "  net = net.to(device)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  class_correct = [0.0] * 10\n",
        "  class_total = [0.0] * 10\n",
        "  class_acc = [0.0] * 10\n",
        "  \n",
        "  metric_values = None\n",
        "  if not (metrics is None):\n",
        "    if isinstance(metrics, dict):\n",
        "      metric_values = {a: 0.0 for a in metrics.keys()}\n",
        "    elif isinstance(metrics, (list, tuple)):\n",
        "      metric_values = {a: 0.0 for a in range(len(metrics))}\n",
        "    else:\n",
        "      metrics = [metrics]\n",
        "      metric_values = {a: 0.0 for a in range(len(metrics))}\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data in dataloader:\n",
        "      inputs, targets = data\n",
        "      \n",
        "      if targets.numel() > 1:\n",
        "        y_true.extend(targets.flatten().tolist())\n",
        "      else:\n",
        "        y_true.append(targets.flatten().tolist())\n",
        "        \n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      \n",
        "      if predicted.numel()>1:\n",
        "        y_pred.extend(predicted.flatten().tolist())\n",
        "      else:\n",
        "        y_pred.append(predicted.flatten().tolist())\n",
        "      \n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "      \n",
        "      c = (predicted == targets).squeeze()\n",
        "      for i in range(targets.size(0)):\n",
        "        label = targets[i]\n",
        "        class_correct[label] += c[i].item()\n",
        "        class_total[label] += 1\n",
        "            \n",
        "    if not (metric_values is None):\n",
        "      for a in metric_values.keys():\n",
        "        metric_values[a] = metrics[a](y_true, y_pred)\n",
        "            \n",
        "  global_acc = correct / max(total, 1.0)\n",
        "  \n",
        "  if verbose:\n",
        "    if metrics is not None:\n",
        "      print('Evaluation on the validation dataset:')\n",
        "      for a in metric_values.keys():\n",
        "        print('Metric {}: {:.0%}'.format(a, metric_values[a]))\n",
        "\n",
        "  for i in range(10):\n",
        "    class_acc[i] = class_correct[i] / max(class_total[i], 1.0)\n",
        "    if verbose:\n",
        "      print('Accuracy of {:<5s} ({}): {:.0%}'\n",
        "            .format(classe_names[i], i, class_acc[i])\n",
        "           )\n",
        "    \n",
        "  return global_acc, class_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbYLAX2Ktt7H"
      },
      "source": [
        "# How much training data is needed?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txSjlglLvaC_"
      },
      "source": [
        "In this section, we study the effect of the training set size on models' performances. We also use a technique called **data augmentation** to artificially create variants of examples with synthetic transformations.\n",
        "\n",
        "Note that we keep the validation set fixed throughout this section. This is just for the purpose of this tutorial, as we want the different evaluations to be comparable. In practice, the validation dataset should never be larger than the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MKcpyiQxl-6"
      },
      "source": [
        "## Training with only 1% of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOm2bCVxy5mc"
      },
      "source": [
        "Let's start by considering only 1% of the training set. The following method allows selecting a portion of data from a given dataset. It takes as input five arguments:\n",
        "- **imgs**: NumPy array representing the image set from which the selection is made.\n",
        "- **labels**: labels associated with the provided image set.\n",
        "- **ratio** (optional): percentage of data that will be selected. Default: `0.1`.\n",
        "- **shuffle** (optional): whether or not the data need to be shuffled before the selection is made. Default: `True`.\n",
        "- **seed** (optional): seed of the random generator: Default: `1234`.\n",
        "\n",
        "It provides as output 2 elements:\n",
        "- **select_imgs**: NumPy array of the selected images.\n",
        "- **select_labels**: labels associated with the selected images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKQZqtge0QoV"
      },
      "source": [
        "def select_subset_from_dataset(imgs, labels, ratio=0.1, shuffle=True, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     imgs: numpy array representing the image set from which \n",
        "        the selection is made.\n",
        "     labels: the labels associated with the provided images.\n",
        "     ratio (optional): percentage of data to be selected. Default: 0.1.\n",
        "     shuffle (optional): Whether or not to shuffle the data. Default: True.\n",
        "     seed (optional): seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of 2 elements (select_imgs, select_labels)\n",
        "     where:\n",
        "        select_imgs: a numpy array of the selected images.\n",
        "        select_labels: labels associated with the selected images.\n",
        "      \n",
        "  \"\"\"\n",
        "  if shuffle:\n",
        "    np.random.seed(seed)  # Set the random seed of numpy.\n",
        "    indices = np.random.permutation(imgs.shape[0])\n",
        "  else:\n",
        "    indices = np.arange(imgs.shape[0])\n",
        "  idx, _ = np.split(indices, [int(ratio*len(indices))])\n",
        "  select_imgs = imgs[idx]\n",
        "  tgt = np.array(labels)\n",
        "  select_labels = tgt[idx].tolist()\n",
        "  return select_imgs, select_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yxgfA30VBbz"
      },
      "source": [
        "We create a new training set that contains only 1% of the original training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWVUZEVTU8-K"
      },
      "source": [
        "train_1percent_imgs, train_1percent_labels  = select_subset_from_dataset(\n",
        "    train_imgs, train_labels, ratio=0.01\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfbVmI7V4dxF"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "Train a model on 1% of the training set and evaluate its performance on the validation set. Use the following values for this experiment:\n",
        "- **epochs**: `50`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy}`.\n",
        "- **eval_imgs**: `valid_imgs`.\n",
        "- **eval_labels**: `valid_labels`.\n",
        "\n",
        "What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UglqJKbYvdpY"
      },
      "source": [
        "# training on selected data\n",
        "model = ... # To complete.\n",
        "\n",
        "# evaluate the trained model on the validation dataset\n",
        "_ = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEMYRMeR8gA8"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRPF8m5Ps7p"
      },
      "source": [
        "## Performance as a function of the dataset size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ILOZAvjPzhB"
      },
      "source": [
        "In the following, We train the same model on various ratios of the training set while keeping the validation set fixed. We want to observe the impact of using larger training sets.\n",
        "\n",
        "The following function performs this study given a list of ratio values. It takes as arguments:\n",
        "- **ratio_list**: list of ratio numbers to be considered in the study.\n",
        "- **epochs** (optional): number of training epochs. Default: `5`.\n",
        "- **seed** (optional): seed of the random generator: Default: `1234`.\n",
        "\n",
        "This function generates a plot showing the accuracy as a function of the ratio of data used for training the model.\n",
        "\n",
        "It is important to note that by fixing the number of epochs, we perform more parameter updates as the training set's size increases. Hence, the overall study is not entirely comparable. However, since the accuracy does not decrease over time in this example, we can still observe the typical phenomenon associated with increasing the training set sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPD0is-Q7ay"
      },
      "source": [
        "def performance_study(ratio_list, epochs=5, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     ratio_list: list of ratio numbers to be considered.\n",
        "     epochs (optional): number of training epochs. Default: 5.\n",
        "     seed (optional): seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     This method does not return anything, but it generates a plot.\n",
        "      \n",
        "  \"\"\"\n",
        "  results = []\n",
        "  for ratio in ratio_list:\n",
        "    select_imgs, select_labels = select_subset_from_dataset(\n",
        "        train_imgs, train_labels, ratio\n",
        "    )\n",
        "    trained_model = training_on_dataset(\n",
        "        select_imgs, select_labels, valid_imgs, valid_labels,\n",
        "        epochs=epochs, batch_size=32,\n",
        "        seed=seed, verbose=False\n",
        "    )\n",
        "    acc, _ = evaluate_classes(\n",
        "        trained_model, valid_imgs, valid_labels, batch_size=32,\n",
        "        verbose=False\n",
        "    )\n",
        "    results.append(acc)\n",
        "  \n",
        "  print('Best accuracy: {:.0%}'.format(max(results)))\n",
        "  plt.plot(ratio_list, results)\n",
        "  plt.title('Model performance on validation set')\n",
        "  plt.xlabel('Training set ratio')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDZLShKzgUMV"
      },
      "source": [
        "### Exercise 6\n",
        "\n",
        "Evaluate the performance using the following ratios: `0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0`. \n",
        "\n",
        "You can choose the number of epochs you wish for this study. Just have in mind that the higher the number, the longer the time required for the training/study. Therefore, it is recommended to not exceed `epochs=20` for the purpose of this tutorial. As a default, it is set to `epochs=5`.\n",
        "\n",
        "Again, by having a fixed number of epochs, the larger the training set, the more often we update the model's parameters.\n",
        "\n",
        "What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS-MkJ_rprdH"
      },
      "source": [
        "ratio_list = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
        "... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hOajcWPAxrC"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dFQG5ViqzM1"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnD2tCAv2QWZ"
      },
      "source": [
        "This section covers data augmentation, which consists of altering the inputs in the training set without changing the associated labels. By doing so, it is possible to augment the number of images in our training set artificially. For example, we can use flipping, cropping, and resizing to alter an image without modifying its associated label. As a result, we may observe some performance gains and better model generalization by learning to be invariant to these transformations. However, since data augmentation is creating artificially new examples from existing ones, the independence assumption is not fully respected. Thus, we should not use data augmentation for the validation and the test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PKpTId_3lGI"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "Assume that we only have access to 30% of the original training dataset. Train a model with this portion of data and evaluate it on the validation dataset. As the number of examples increases in the training set, we may consider increasing the number of epochs while keeping in mind the overfitting problem. For this exercise, we will use the following arguments:\n",
        "- **epochs**: `15`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy}`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pBFLLmxrCC8"
      },
      "source": [
        "# select the data\n",
        "train_30percent_imgs, train_30percent_labels = ... # To complete.\n",
        "\n",
        "# training on selected data\n",
        "model = ... # To complete.\n",
        "\n",
        "# evaluate on the validation dataset\n",
        "_ = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdeKH-JsrcPl"
      },
      "source": [
        "### Exercise 8\n",
        "\n",
        "The following code defines a transformation pipeline using the torchvision utilities. The `RandomResizedCrop` operation takes a random crop of the image with a relative size between 0.7 and 1.0. Then, this crop is resized to a 32 x 32 image. The transformations are applied to the original images at every mini-batch generation leaving the dataset's images unchanged; only the mini-batch images are copied and transformed at every iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5h0bzG9rh_T"
      },
      "source": [
        "transformations = transforms.Compose([\n",
        "    transforms.Normalize((-1., -1., -1.), (2., 2., 2.)),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop((32, 32), scale=(0.7, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "110l_poa5AUi"
      },
      "source": [
        "Now, we train a new model by applying data augmentation to the same training set used in the previous exercise. Use the following arguments:\n",
        "- **epochs**: `25`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy}`.\n",
        "\n",
        "and the argument `transformations` of the `training_on_dataset` method to perform data augmentation during training.\n",
        "\n",
        "Evaluate your model and compare your results with those from the previous exercise. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JHCgdzprnG9"
      },
      "source": [
        "# training on selected data with data augmentation techniques\n",
        "model_aug = ... # To complete.\n",
        "\n",
        "# evaluate on the validation dataset\n",
        "_ = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP24gLYYIia_"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRbANE0mjLY"
      },
      "source": [
        "# Unbalanced datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfpH0Cx1NA-z"
      },
      "source": [
        "## What is an unbalanced dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDuyTs_smng1"
      },
      "source": [
        "Up to now, the training dataset contained about the same number of images for each label. This section explores the impact of training models on an unbalanced dataset, which happens when each class does not make up an equal portion of your dataset. \n",
        "\n",
        "The following function selects a portion of data from a given dataset while providing a defined label distribution. It takes as input six arguments:\n",
        "- **imgs**: NumPy array representing the image set from which the selection is made.\n",
        "- **labels**: labels associated with the provided image set.\n",
        "- **label_dist**: the distribution of labels to be selected, represented by a dict of `{label: value}`.\n",
        "- **ratio** (optional): percentage of the data that will be selected. Default: `0.1`.\n",
        "- **shuffle** (optional): whether or not the data need to be shuffled before the selection is made. Default: `True`.\n",
        "- **seed** (optional): seed of the random generator: Default: `1234`.\n",
        "\n",
        "It provides as output 2 elements:\n",
        "- **select_imgs**: a NumPy array of the selected images.\n",
        "- **select_labels**: labels associated with the selected images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx4E8E5TLr2H"
      },
      "source": [
        "def select_subset_from_dataset_with_label_dist(\n",
        "    imgs, labels, label_dist, ratio=0.1, shuffle=True, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     imgs: numpy array representing the image set from which \n",
        "        the selection is made.\n",
        "     labels: the labels associated with the provided images.\n",
        "     label_dist: the distribution of labels to select.\n",
        "     ratio (optional): percentage of the data to be selected. Default: 0.1.\n",
        "     shuffle (optional): Whether or not to shuffle the data. Default: True.\n",
        "     seed (optional): seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of 2 elements (select_imgs, select_labels)\n",
        "     where:\n",
        "        select_imgs: a numpy array of the selected images.\n",
        "        select_labels: labels associated with the selected images.\n",
        "      \n",
        "  \"\"\"\n",
        "  if isinstance(label_dist, (list, tuple)):\n",
        "    label_dist = {a:v for a,v in enumerate(label_dist)}\n",
        "  sum_dist = sum(label_dist.values())\n",
        "  for lab in label_dist.keys():\n",
        "    label_dist[lab] /= sum_dist\n",
        "    \n",
        "  tgts = np.array(labels)\n",
        "  num_indices = int(ratio*len(labels))\n",
        "  num_idx_lab = {a: int(label_dist[a]*num_indices) for a in label_dist.keys()}\n",
        "  \n",
        "  sel_ind = []\n",
        "  \n",
        "  if shuffle:\n",
        "    np.random.seed(seed)  # Set the random seed of numpy.\n",
        "\n",
        "  for a in num_idx_lab.keys():\n",
        "    idx = np.where(tgts==a)\n",
        "    idx = idx[0]\n",
        "    if shuffle:\n",
        "      idx = np.random.permutation(idx)\n",
        "    num = min(num_idx_lab[a], len(idx))\n",
        "    idx = idx[0:num]\n",
        "    sel_ind.extend(idx)\n",
        "    \n",
        "  if shuffle:\n",
        "    sel_ind = np.random.permutation(sel_ind)\n",
        "  else:\n",
        "    sel_ind.sort()\n",
        "    sel_ind = np.array(sel_ind)\n",
        "    \n",
        "  select_imgs = imgs[sel_ind, :]\n",
        "  select_labels = tgts[sel_ind].tolist()\n",
        "  \n",
        "  return select_imgs, select_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQO9ejo57_G1"
      },
      "source": [
        "### Exercise 9\n",
        "\n",
        "Using the function `select_subset_from_dataset_with_label_dist`, extract 30% of the training set with the following label distribution:\n",
        "- **0**: `0.4`.\n",
        "- **1**: `0.1`.\n",
        "- **2**: `0.05`.\n",
        "- **3**: `0.01`.\n",
        "- **4**: `0.2`.\n",
        "- **5**: `0.14`.\n",
        "- **6**: `0.02`.\n",
        "- **7**: `0.005`.\n",
        "- **8**: `0.045`.\n",
        "- **9**: `0.03`.\n",
        "\n",
        "Also, extract 40% of the validation set with the same label distribution.\n",
        "\n",
        "Compute the histograms of the resulting datasets and compare their relative frequencies.\n",
        "\n",
        "Note that the relative frequencies may not be exactly equal to the label distribution but should be close enough for our purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-irncrQq4MD-"
      },
      "source": [
        "label_distribution = {\n",
        "    0: 0.23,\n",
        "    1: 0.14,\n",
        "    2: 0.07,\n",
        "    3: 0.01,\n",
        "    4: 0.23, \n",
        "    5: 0.19,\n",
        "    6: 0.02,\n",
        "    7: 0.01,\n",
        "    8: 0.07,\n",
        "    9: 0.03\n",
        "}\n",
        "\n",
        "# select data according to a provided distribution\n",
        "... # To complete.\n",
        "\n",
        "# plot the histogram of the selected labels\n",
        "... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Z9BMTZN36h"
      },
      "source": [
        "## Is accuracy a good metric for an unbalanced dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47WPFK9zOaxz"
      },
      "source": [
        "### Exercise 10\n",
        "\n",
        "Train a model using the unbalanced traning set and evaluate its performance on the unbalanced validation set. Use the following arguments:\n",
        "- **epochs**: `20`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy, 'F1': f1_score}`.\n",
        "\n",
        "When we have an unbalanced dataset, using [F1-score](https://en.wikipedia.org/wiki/F-score) is usually recommended. The F1-score is the harmonic mean of the [Precision and Recall scores](https://en.wikipedia.org/wiki/Precision_and_recall).\n",
        "\n",
        "Compare the global accuracy with the accuracies per class. What do you observe? What the F1-score evaluates better than the accuracy in this case?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxnLmJWo-Xze"
      },
      "source": [
        "# training on selected data\n",
        "modelUnbal = ... # To complete.\n",
        "\n",
        "# evaluate on the validation dataset\n",
        "_ = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NruL0f6L-Ps"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdwjfGNmTST_"
      },
      "source": [
        "## Dealing with unbalanced datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz8TGOohTcJ_"
      },
      "source": [
        "One way to mitigate the consequences of an unbalanced dataset during the training process is to penalize the model more when it makes prediction errors on less frequent classes. A way to achieve this is to assign importance weights to examples that are the inverse relative frequency of their class within the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3iJ_-vWVG9Y"
      },
      "source": [
        "### Exercise 11\n",
        "\n",
        "Compute the importance weights of each label using the label distribution provided in the previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiS2HFH9IbNe"
      },
      "source": [
        "label_weights = ... # To complete.\n",
        "\n",
        "for i, w in enumerate(label_weights):\n",
        "  print('Importance weight for {:<5s} ({}): {:.1f}'.format(classe_names[i], i, w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntkItzYLVN8I"
      },
      "source": [
        "### Exercise 12\n",
        "\n",
        "Using the importance weights computed above, train a model using the extracted training dataset and evaluate its performance on the original validation dataset. For the sake of fair comparisons, use the same arguments as in the previous exercise:\n",
        "- **epochs**: `15`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy, 'F1': f1_score}`.\n",
        "\n",
        "Note that the importance weights could be passed to the training method using the argument `label_weights`.\n",
        "\n",
        "What do you observe?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACbafl1BGgTw"
      },
      "source": [
        "# training on selected data\n",
        "modelUnbal = ... # To complete.\n",
        "\n",
        "# evaluate on the validation dataset\n",
        "_ = ... # To complete.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5w8vbPPmaV6"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4QJ0cBCe483"
      },
      "source": [
        "# Reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfk8gF1pG8oo"
      },
      "source": [
        "We have seen that there is randomness in machine learning experiments, precisely when:\n",
        "- splitting an original dataset into training/validation/test sets.\n",
        "- initializing the parameters of a model.\n",
        "- shuffling the training set after each epoch when training the model.\n",
        "\n",
        "Therefore, we usually get different results each time we run the same experiment. It is required to fix the **random seed** at the very beginning of your experiment. Hence, it is best practice to manually set:\n",
        "\n",
        "1. Python pseudorandom number generator at a fixed value:\n",
        "```\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "```\n",
        "\n",
        "2. NumPy pseudorandom number generator at a fixed value:\n",
        "```\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "```\n",
        "\n",
        "3. PyTorch pseudorandom number generator at a fixed value for all devices (both CPU and GPU):\n",
        "```\n",
        "import torch\n",
        "torch.manual_seed(seed_value)\n",
        "```\n",
        "\n",
        "4. PyTorch pseudorandom number generator at a fixed value for the GPU(s):\n",
        "```\n",
        "import torch\n",
        "torch.cuda.manual_seed(seed_value)  # Current GPU.\n",
        "torch.cuda.manual_seed_all(seed_value)  # All GPUs.\n",
        "```\n",
        "\n",
        "5. CuDNN algorithms (an extension of CUDA for deep learning) to be deterministic in PyTorch:\n",
        "```\n",
        "import torch\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "```\n",
        "\n",
        "Note that deterministic algorithms can make computations dramatically slower. While manually fixing random seeds helps reproducibility, completely reproducible results are not guaranteed across PyTorch releases and different platforms, devices, or drivers.\n",
        "\n",
        "Furthermore, more randomness comes in when doing hyperparameter tuning or using multiple GPU devices in parallel, but that's beyond the scope of this tutorial.\n",
        "\n",
        "Finally, a good practice, implemented in Scikit-Learn, is to create a local RandomState object instead of using the global RandomState object and to pass it to every module using randomness. However, the Pytorch API does not allow it, and for now, using global RNGs is recommended."
      ]
    }
  ]
}